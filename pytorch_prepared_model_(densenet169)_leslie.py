# -*- coding: utf-8 -*-
"""PyTorch Prepared model (densenet169) Leslie.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RminLLa4AfgjAZqMjQhUntvYXKnuGGEV
"""

import importlib
import numpy as np
import pandas as pd
import pydicom
import os
import collections
import sys
import glob
import random
import cv2
# import tensorflow as tf
import multiprocessing
import matplotlib.pyplot as plt

import torch
from torch import nn
from torch import optim
from torchvision import models
from torchvision import datasets, transforms
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
import torch.nn.functional as F
import time

from math import ceil, floor
from copy import deepcopy
from tqdm import tqdm_notebook as tqdm
from imgaug import augmenters as iaa

# import keras
# import keras.backend as K
# from keras.callbacks import Callback, ModelCheckpoint
# from keras.applications import DenseNet121, DenseNet169
# from keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D
# from keras.models import Model, load_model
# from keras.utils import Sequence
# from keras.losses import binary_crossentropy
# from keras.optimizers import Adam

"""Install and import the efficientnet and iterative-stratification packages from the internet. The iterative-stratification package provides a very nice implementation of multi-label stratification. I've used it in a few competitions now with good results. There are offcourse more packages that provide implementations for it."""

# Import Custom Modules
# import efficientnet.keras as efn
from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit

"""Next we will set the random_state, some constants and folders that will be used later on. I've specified a rather small test size as I want to maximize the training time available and minimize the time used for validation. I'am not using methods like early stopping...when the kernel time limit is approaching we could still increase the results on the LB if we were allowed to continue."""

# Seed
SEED = 12345
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

# Constants
TEST_SIZE = 0.02
CHANNELS = 3
HEIGHT = 256
WIDTH = 256
TRAIN_BATCH_SIZE = 32
VALID_BATCH_SIZE = 64
# SHAPE = (CHANNELS, HEIGHT, WIDTH)

# Folders
DATA_DIR = 'C:/Users/Lesli/Documents/Doc administratif/2024-2025/Madrid/Stage/Prepared model/'
TEST_IMAGES_DIR = DATA_DIR + 'stage_2_test/'
TRAIN_IMAGES_DIR = DATA_DIR + 'stage_2_train/'

test_image_ids = os.listdir(TEST_IMAGES_DIR)
sample_image_dir = os.path.join(TEST_IMAGES_DIR, test_image_ids[0])
dicom_image = pydicom.dcmread(sample_image_dir)

# Afficher l'image
plt.imshow(dicom_image.pixel_array, cmap="gray")  # cmap="gray" pour affichage en niveaux de gris
plt.axis("off")  # Supprimer les axes
plt.show()

"""Next the code for the DICOM windowing and the Data Generators. After seeing the effect of different versions of windowing as presented in this very nice [kernel](https://www.kaggle.com/akensert/inceptionv3-prev-resnet50-keras-baseline-model) I decided to also update my kernel with it. Lets see what the effect will be."""

def correct_dcm(dcm):
    x = dcm.pixel_array + 1000
    px_mode = 4096
    x[x>=px_mode] = x[x>=px_mode] - px_mode
    dcm.PixelData = x.tobytes()
    dcm.RescaleIntercept = -1000

def window_image(dcm, window_center, window_width):
    if (dcm.BitsStored == 12) and (dcm.PixelRepresentation == 0) and (int(dcm.RescaleIntercept) > -100):
        correct_dcm(dcm)
    img = dcm.pixel_array.astype(np.float32) * dcm.RescaleSlope + dcm.RescaleIntercept

    img = torch.from_numpy(img).unsqueeze(0).unsqueeze(0)  # shape [1, 1, H, W]
    img = F.interpolate(img, size=(HEIGHT, WIDTH)[:2], mode='bilinear', align_corners=False)
    img = img.squeeze(0).squeeze(0)  # back to shape [H, W]

    img_min = window_center - window_width // 2
    img_max = window_center + window_width // 2
    img = torch.clamp(img, min=img_min, max=img_max)

    return img

def bsb_window(dcm):
    brain_img = window_image(dcm, 40, 80)
    subdural_img = window_image(dcm, 80, 200)
    soft_img = window_image(dcm, 40, 380)
    brain_img = (brain_img - 0) / 80
    subdural_img = (subdural_img - (-20)) / 200
    soft_img = (soft_img - (-150)) / 380
    bsb_img = torch.stack([brain_img, subdural_img, soft_img])
    return bsb_img

def _read(path, SHAPE):
    dcm = pydicom.dcmread(path)
    try:
        img = bsb_window(dcm)
    except:
        img = torch.zeros((CHANNELS, HEIGHT, WIDTH))
    return img

"""I'll specify some light image augmentation. Some horizontal and vertical flipping and some cropping. I haven't yet tried out more augmentation but will do so in future versions of the kernel. Also the code for Data Generators for train and test data."""

# Image Augmentation
def sometimes(prob, transform):
    return transforms.RandomApply([transform], p=prob)

# augmentation = transforms.Compose([
#     transforms.RandomHorizontalFlip(p=0.25),
#     transforms.RandomVerticalFlip(p=0.10),
#     sometimes(0.25, transforms.RandomResizedCrop(size=(256, 256), scale=(0.8, 1.0))),
# ])

# Dataset Generators
class TrainDataset(Dataset):
    def __init__(self, dataset, labels, batch_size, img_size = (CHANNELS, HEIGHT, WIDTH), img_dir = TRAIN_IMAGES_DIR, augment = False):
        self.dataset = dataset
        self.labels = labels
        self.ids = dataset.index.tolist()
        self.batch_size = batch_size
        self.img_size = img_size
        self.img_dir = img_dir
        self.augment = augment
        self.transform = self.get_transforms()

    def get_transforms(self):
        base_transforms = []
        if self.augment:
            base_transforms += [
                transforms.RandomHorizontalFlip(p=0.25),
                transforms.RandomVerticalFlip(p=0.10),
                sometimes(0.25, transforms.RandomResizedCrop(size=(self.img_size[1], self.img_size[2]), scale=(0.8, 1.0)))
            ]
        return transforms.Compose(base_transforms)

    def __len__(self):
        return len(self.ids)

    def __getitem__(self, index):
        ID = self.ids[index]
        image_path = os.path.join(self.img_dir, ID + ".dcm")

        image = _read(image_path, self.img_size)

        image = self.transform(image)

        label = torch.tensor(self.labels.iloc[index].values, dtype=torch.float32)

        return image, label

class TestDataset(Dataset):
    def __init__(self, dataset, labels, batch_size = 16, img_size = (CHANNELS, HEIGHT, WIDTH), img_dir = TEST_IMAGES_DIR, *args, **kwargs):
        self.dataset = dataset
        self.ids = dataset.index.tolist()
        self.labels = labels
        self.img_size = img_size
        self.img_dir = img_dir

    def __len__(self):
        return len(self.ids)

    def __getitem__(self, index):
        ID = self.ids[index]
        image_path = os.path.join(self.img_dir, ID + ".dcm")

        image = _read(image_path, self.img_size)

        label = torch.zeros(6)

        return image, label

"""Import the training and test datasets."""

def read_testset(filename = DATA_DIR + "stage_2_sample_submission.csv"):
    df = pd.read_csv(filename)
    df["Image"] = df["ID"].str.slice(stop=12)
    df["Diagnosis"] = df["ID"].str.slice(start=13)
    df = df.loc[:, ["Label", "Diagnosis", "Image"]]
    df = df.set_index(['Image', 'Diagnosis']).unstack(level=-1)
    return df

def read_trainset(filename = DATA_DIR + "stage_2_train.csv"):
    df = pd.read_csv(filename)
    df["Image"] = df["ID"].str.slice(stop=12)
    df["Diagnosis"] = df["ID"].str.slice(start=13)
    duplicates_to_remove = [56346, 56347, 56348, 56349,
                            56350, 56351, 1171830, 1171831,
                            1171832, 1171833, 1171834, 1171835,
                            3705312, 3705313, 3705314, 3705315,
                            3705316, 3705317, 3842478, 3842479,
                            3842480, 3842481, 3842482, 3842483 ]
    df = df.drop(index = duplicates_to_remove)
    df = df.reset_index(drop = True)
    df = df.loc[:, ["Label", "Diagnosis", "Image"]]
    df = df.set_index(['Image', 'Diagnosis']).unstack(level=-1)
    return df

# Read Train and Test Datasets
test_df_all = read_testset()
train_df_all = read_trainset()

print(test_df_all.shape)
print(train_df_all.shape)

test_image_ids = [id.replace('.dcm', '') for id in test_image_ids]
test_df = test_df_all[test_df_all.index.isin(test_image_ids)]
print(test_df.shape)

train_image_ids = os.listdir(TRAIN_IMAGES_DIR)
train_image_ids = [id.replace('.dcm', '') for id in train_image_ids]
train_df = train_df_all[train_df_all.index.isin(train_image_ids)]
print(train_df.shape)

"""The training data contains some class inbalance. Multiple kernels explored the use of undersampling..so let's try the opposite and oversample the minority class 'epidural' one additional time."""

# Oversampling
epidural_df = train_df[train_df.Label['epidural'] == 1]
train_oversample_df = pd.concat([train_df, epidural_df])
train_df = train_oversample_df

# Summary
print('Train Shape: {}'.format(train_df.shape))
print('Test Shape: {}'.format(test_df.shape))

"""Some methods for predictions on the test data, a callback method and a method to create the EfficientNet B2 model. For the EfficientNet we use the pretrained imagenet weights. Also a Dropout layer is added with a small value to prevent some overfitting."""
# def ModelCheckpointFull(model_name):
#     return ModelCheckpoint(model_name,
#                             monitor = 'val_loss',
#                             verbose = 1,
#                             save_best_only = False,
#                             save_weights_only = True,
#                             mode = 'min',
#                             save_freq='epoch')  # Replaces 'period=1'

class Model(nn.Module):
    def __init__(self, in_features, prob):
        super().__init__()
        self.gap = nn.AdaptiveAvgPool2d(1)
        self.dropout = nn.Dropout(p=prob)
        self.output = nn.Linear(in_features, 6)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        # x = self.gap(x)
        # x = x.view(x.size(0), -1)
        x = self.dropout(x)
        x = self.output(x)
        # x = self.sigmoid(x)

        return x

model = models.densenet169(pretrained=True)
# Freeze parameters so we don't backprop through them
for param in model.parameters():
    param.requires_grad = False

in_features = model.classifier.in_features
model.classifier = Model(in_features, prob = 0.15)

"""Next we setup the multi label stratification. I've specified multiple splits but only using the first one for train data and validation data. Optionally you can also loop through the different splits and use a different train and validation set for each epoch."""

# Submission Placeholder
submission_predictions = []

# Perform stratified split
msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=TEST_SIZE, random_state=SEED)
X = train_df.index
Y = train_df.Label.values
train_idx, valid_idx = next(msss.split(X, Y))

labels = [('Label',              'any'),
            ('Label',         'epidural'),
            ('Label', 'intraparenchymal'),
            ('Label', 'intraventricular'),
            ('Label',     'subarachnoid'),
            ('Label',         'subdural')]

# Train Dataset
train_dataset = TrainDataset(
    dataset=train_df.iloc[train_idx],
    labels=train_df.iloc[train_idx][labels],
    batch_size=TRAIN_BATCH_SIZE,
    img_dir=TRAIN_IMAGES_DIR,
    augment=True
)

# Validation Dataset
valid_dataset = TrainDataset(
    dataset=train_df.iloc[valid_idx],
    labels=train_df.iloc[valid_idx][labels],
    batch_size=VALID_BATCH_SIZE,
    img_dir=TRAIN_IMAGES_DIR,
    augment=False
)

# Test Dataset
test_dataset = TestDataset(
    dataset=test_df,
    labels=None,
    img_dir=TEST_IMAGES_DIR
)

# Create DataLoaders
trainloader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)
validloader = DataLoader(valid_dataset, batch_size=VALID_BATCH_SIZE, shuffle=False)
testloader = DataLoader(test_dataset, batch_size=16, shuffle=False)

"""Now we can train the model for a number of epochs. All epochs we train the full model but each time on only 1/6 of the train data. With each epoch only a subset of the train data will allow us to make more epochs and allows todo averaging over more then just 1 or 2 epochs (compared to using all data every epoch).

Note that I recreate the data generators and model on each epoch. This is only necessary when using the different Multi-label stratified splits since the data generators will get a totally different set of data on each epoch then. I left it in so that you can try it out.

Starting with the 4th epoch a prediction for the test set is made on each epoch. In total predictions from the last 5 epochs will be averaged this way for the final submission.
"""

# Commented out IPython magic to ensure Python compatibility.
class Model_extented(nn.Module):
    def __init__(self,model, epochs,lr):
        super().__init__()
        self.model = model
        self.epochs = epochs
        self.lr = lr
        self.optim = optim.Adam(self.model.classifier.parameters(), self.lr)
        self.loss_function = nn.BCEWithLogitsLoss()
        self.loss_during_training = []
        self.valid_loss_during_training = []
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu") #to run on gpu if available
        self.model.to(self.device)

    def forward(self, x):
        return self.model(x)

    def trainloop(self, trainloader, validloader):
        self.model.train()
        for epoch in range (self.epochs):
            print(f'=========== EPOCH {epoch}')
            start_time = time.time()
            running_loss = 0.0
            for inputs, labels in trainloader:
                inputs, labels = inputs.to(self.device), labels.float().to(self.device)
                self.optim.zero_grad()
                outputs = self.forward(inputs)
                loss = self.loss_function(outputs, labels)
                loss.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                running_loss += loss.item()
                self.optim.step()

            self.loss_during_training.append(running_loss/len(trainloader))

            # Validation mode
            self.model.eval()
            with torch.no_grad():
                val_loss = 0.0
                for inputs, labels in validloader:
                    inputs, labels = inputs.to(self.device), labels.to(self.device)
                    outputs = self.forward(inputs)
                    loss = self.loss_function(outputs, labels)
                    val_loss += loss.item()

                self.valid_loss_during_training.append(val_loss/len(validloader))

            # torch.save(model.state_dict(), '/content/drive/MyDrive/Stage Madrid/densenet169_model.weights.pth')

            if epoch >= 3:
                preds_list = []

                with torch.no_grad():
                    for inputs, _ in testloader:
                        inputs = inputs.to(self.device)
                        outputs = self.forward(inputs)

                        probs = torch.sigmoid(outputs)
                        preds_list.append(probs.cpu())

                preds = torch.cat(preds_list, dim=0).numpy()
                submission_predictions.append(preds)

            self.model.train()
            print("Training loss: %f, Validation loss: %f, Time per epoch: %f seconds"
                       %(self.loss_during_training[-1],self.valid_loss_during_training[-1],
                       (time.time() - start_time)))


    def eval_performance(self,dataloader):
        loss = 0
        accuracy = 0
        self.model.eval()
        # Turn off gradients for validation, saves memory and computations
        with torch.no_grad():
            for inputs,labels in dataloader:
                inputs, labels = inputs.to(self.device), labels.to(self.device)
                print("labels : ", labels)
                outputs = self.forward(inputs)
                print("outputs : ", outputs)
                probs = torch.sigmoid(outputs)
                print("probs : ",probs)

                predicted_labels = (probs > 0.5).float() # Get predicted labels based on threshold
                equals = (predicted_labels == labels) # Compare predicted and actual labels
                accuracy += torch.mean(equals.type(torch.FloatTensor)).item() # Calculate accuracy

            self.model.train()
            return accuracy/len(dataloader)

    def saliency(self, dataloader, index):
        self.model.eval()
        for inputs, _ in dataloader:
            input_img = inputs[index].unsqueeze(0).to(self.device)
            input_img.requires_grad = True

            output = self.forward(input_img)
            probs = torch.sigmoid(output)

            # Get the class with the highest predicted score
            score, _ = torch.max(probs, dim=1)
            score.backward()
            # Get the saliency map: max of gradients across channels
            saliency_map, _ = torch.max(torch.abs(input_img.grad[0]), dim=0)
            saliency_map = (saliency_map - saliency_map.min()) / (saliency_map.max() - saliency_map.min())

            # Visualization
            plt.figure(figsize=(10, 5))
            plt.subplot(1, 2, 1)
            img_np = input_img.detach().cpu().squeeze().permute(1, 2, 0).numpy()
            plt.imshow(img_np, cmap='gray' if img_np.shape[2] == 1 else None)
            plt.title("Original Image")
            plt.axis("off")
            plt.subplot(1, 2, 2)
            plt.imshow(saliency_map.cpu(), cmap='hot')
            plt.title("Saliency Map")
            plt.axis("off")
            plt.tight_layout()
            plt.show()

            break  # Only one image!
        self.model.train()

my_model=Model_extented(model, epochs=6,lr=0.0001)
my_model.trainloop(trainloader, validloader)

plt.plot(my_model.loss_during_training,label='Training Loss')
plt.plot(my_model.valid_loss_during_training,label='Validation Loss')
plt.legend()

print(my_model.eval_performance(trainloader))
print(my_model.eval_performance(validloader))

print(my_model.saliency(testloader, index=0))

"""And finally we create the submission file by averaging all submission_predictions."""

test_df_f = test_df.copy()

reshaped_predictions = np.vstack(submission_predictions)
# averaged_preds = np.average(reshaped_predictions, axis=0, weights=[2**i for i in range(len(submission_predictions))])
averaged_preds = np.average(reshaped_predictions, axis=0)
# averaged_preds = averaged_preds.reshape(test_df.shape[0], test_df.shape[1])
test_df_f.iloc[:, :] = averaged_preds

test_df_f = test_df_f.stack().reset_index()
test_df_f.insert(loc = 0, column = 'ID', value = test_df_f['Image'].astype(str) + "_" + test_df_f['Diagnosis'])
test_df_f = test_df_f.drop(["Image", "Diagnosis"], axis=1)
# test_df_f.to_csv('densenet169_submission_new.csv', index = False)
print(test_df_f)
print("Label Min : ", test_df_f["Label"].min())
print("Label Max : ",test_df_f["Label"].max())

# test_df_submission_all = pd.read_csv(DATA_DIR+'densenet169_submission.csv') #results of someone else
# test_df_submission = test_df_submission_all[test_df_submission_all['ID'].isin(test_df_f['ID'])]
# print("test_df_submission.shape", test_df_submission.shape)

# df_comparaison = test_df_submission.merge(test_df_f, on="ID")
# df_comparaison["Difference"] = abs(df_comparaison["Label_x"] - df_comparaison["Label_y"])
# print(df_comparaison.tail(50))
# print("Max diffence : ", df_comparaison["Difference"].max())
# print("Difference mean : ", df_comparaison["Difference"].mean())
# print("Max Label : ",df_comparaison["Label_y"].max())